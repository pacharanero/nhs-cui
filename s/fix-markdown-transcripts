#!/usr/bin/env python3
"""Normalize generated markdown transcripts without changing wording semantics."""

from __future__ import annotations

import argparse
import os
import re
from collections import Counter
from pathlib import Path

TOC_START = "<!-- TOC -->"
TOC_END = "<!-- /TOC -->"
TOC_NOTE = "<!-- TOC generated by Markdown All in One style -->"
SOURCE_PREFIX = "Source PDF:"

LIGATURES = {
    "ﬁ": "fi",
    "ﬂ": "fl",
    "ﬀ": "ff",
    "ﬃ": "ffi",
    "ﬄ": "ffl",
}

BULLET_RE = re.compile(r"^(\s*)[•·●○▪■◦]\s+")
ORDERED_RE = re.compile(r"^\s*\d+[.)]\s+")
HEADER_RE = re.compile(r"^(#{1,6})\s+(.+?)\s*$")
CONTENTS_TITLE_RE = re.compile(r"^(table of contents|contents)$", re.I)
TOC_ENTRY_DOTTED_RE = re.compile(r"\.{4,}\s*\d+\s*$")
TOC_ENTRY_BOLD_PAGE_RE = re.compile(r"^\*\*.+\*\*\s+\*\*\d+\*\*\s*$")
TOC_ENTRY_SECTION_RE = re.compile(r"^\d+(\.\d+)*\s+.+\s+\d+\s*$")
TOC_PAGE_MARKER_RE = re.compile(r"^page\s+([ivxlcdm]+|\d+)$", re.I)


def is_structural(line: str) -> bool:
    s = line.lstrip()
    if not s:
        return True
    if s.startswith(("#", ">", "```", "~~~", "|", "![", "<!--")):
        return True
    if s.startswith(("- ", "* ", "+ ")):
        return True
    if ORDERED_RE.match(s):
        return True
    if re.match(r"^[-_*]{3,}\s*$", s):
        return True
    return False


def is_style_only_line(line: str) -> bool:
    s = line.strip()
    if not s:
        return False
    return bool(
        re.match(r"^(\*\*[^*]+\*\*|_[^_]+_|\*[^*]+\*|`[^`]+`)$", s)
        or re.match(r"^\*\*.+\*\*\s+\*\*.+\*\*$", s)
    )


def cleanup_punctuation_spacing(text: str) -> tuple[str, int]:
    n = 0

    def repl(m: re.Match[str]) -> str:
        nonlocal n
        n += 1
        return f"{m.group(1)}{m.group(2)}"

    text = re.sub(r'([\w\)\]\}"])[ \t]+([,;:.!?])', repl, text)
    return text, n


def strip_md_formatting(text: str) -> str:
    t = text
    t = re.sub(r"`([^`]+)`", r"\1", t)
    t = re.sub(r"\*\*([^*]+)\*\*", r"\1", t)
    t = re.sub(r"_([^_]+)_", r"\1", t)
    t = re.sub(r"\*([^*]+)\*", r"\1", t)
    t = re.sub(r"\[(.*?)\]\([^)]*\)", r"\1", t)
    t = re.sub(r"<[^>]+>", "", t)
    return t.strip()


def anchor_slug(title: str) -> str:
    t = strip_md_formatting(title).lower()
    t = re.sub(r"[^a-z0-9\-\s]", "", t)
    t = re.sub(r"\s+", "-", t).strip("-")
    return t


def build_toc(lines: list[str]) -> list[str]:
    items: list[tuple[int, str, str]] = []
    seen: set[str] = set()
    for line in lines:
        m = HEADER_RE.match(line)
        if not m:
            continue
        level = len(m.group(1))
        title = m.group(2).strip()
        if strip_md_formatting(title).upper() in {"TABLE OF CONTENTS", "CONTENTS"}:
            continue
        slug = anchor_slug(title)
        if not slug:
            continue
        if slug in seen:
            continue
        seen.add(slug)
        items.append((level, strip_md_formatting(title), slug))

    if not items:
        return []

    base_level = min(level for level, _, _ in items)
    toc = [TOC_START, TOC_NOTE, ""]
    for level, title, slug in items:
        indent = "  " * max(0, level - base_level)
        toc.append(f"{indent}- [{title}](#{slug})")
    toc.extend(["", TOC_END])
    return toc


def normalize_heading_markup(lines: list[str]) -> tuple[list[str], int]:
    out: list[str] = []
    changed = 0
    for line in lines:
        m = HEADER_RE.match(line)
        if not m:
            out.append(line)
            continue
        hashes = m.group(1)
        heading_text = m.group(2).strip()
        normalized_text = strip_md_formatting(heading_text)
        if normalized_text and normalized_text != heading_text:
            out.append(f"{hashes} {normalized_text}")
            changed += 1
        else:
            out.append(line)
    return out, changed


def is_contents_marker(line: str) -> bool:
    text = strip_md_formatting(line).strip()
    return bool(CONTENTS_TITLE_RE.match(text))


def is_legacy_toc_entry_line(line: str) -> bool:
    stripped = line.strip()
    if stripped == "":
        return True
    plain = strip_md_formatting(stripped)
    if TOC_ENTRY_DOTTED_RE.search(plain):
        return True
    if TOC_ENTRY_BOLD_PAGE_RE.match(stripped):
        return True
    if TOC_ENTRY_SECTION_RE.match(plain):
        return True
    if TOC_PAGE_MARKER_RE.match(plain):
        return True
    if plain in {"HSCIC Controlled Document", "Copyright ©2013 Health and Social Care Information Centre"}:
        return True
    # Example: "Executive Summary 1"
    if re.match(r"^[A-Za-z].+\s+\d+$", plain) and len(plain.split()) <= 10:
        return True
    return False


def remove_legacy_contents_sections(lines: list[str]) -> tuple[list[str], int, int]:
    out: list[str] = []
    i = 0
    sections_removed = 0
    lines_removed = 0

    while i < len(lines):
        line = lines[i]
        heading_match = HEADER_RE.match(line)
        is_heading_contents = False
        if heading_match:
            title = strip_md_formatting(heading_match.group(2))
            is_heading_contents = bool(CONTENTS_TITLE_RE.match(title))

        is_standalone_contents = is_contents_marker(line)
        if not is_heading_contents and not is_standalone_contents:
            out.append(line)
            i += 1
            continue

        # Drop the marker line, then drop TOC-style entry lines immediately after.
        sections_removed += 1
        lines_removed += 1
        i += 1
        while i < len(lines):
            candidate = lines[i]
            if is_legacy_toc_entry_line(candidate):
                lines_removed += 1
                i += 1
                continue
            break
        # Preserve exactly one blank line boundary if needed.
        if out and out[-1].strip() != "":
            out.append("")

    return out, sections_removed, lines_removed


def remove_preamble_toc_fragments(lines: list[str]) -> tuple[list[str], int]:
    """Remove TOC-like residue in preamble before first numbered section heading."""
    first_numbered_heading_index = None
    for idx, line in enumerate(lines):
        m = HEADER_RE.match(line)
        if m and re.match(r"^\d", strip_md_formatting(m.group(2))):
            first_numbered_heading_index = idx
            break

    if first_numbered_heading_index is None:
        return lines, 0

    removed = 0
    out = lines[:]
    i = 0
    while i < first_numbered_heading_index:
        candidate = out[i]
        if is_legacy_toc_entry_line(candidate):
            out.pop(i)
            first_numbered_heading_index -= 1
            removed += 1
            continue
        i += 1

    # collapse blank lines after preamble pruning
    collapsed: list[str] = []
    blanks = 0
    for line in out:
        if line.strip() == "":
            blanks += 1
            if blanks <= 1:
                collapsed.append("")
        else:
            blanks = 0
            collapsed.append(line)
    return collapsed, removed


def remove_existing_toc(lines: list[str]) -> tuple[list[str], int]:
    try:
        i = lines.index(TOC_START)
        j = lines.index(TOC_END, i + 1)
        return lines[:i] + lines[j + 1 :], 1
    except ValueError:
        return lines, 0


def remove_existing_source_line(lines: list[str]) -> tuple[list[str], int]:
    removed = 0
    out: list[str] = []
    for line in lines:
        if line.strip().startswith(SOURCE_PREFIX):
            removed += 1
            continue
        out.append(line)
    return out, removed


def reflow_lines(lines: list[str]) -> tuple[list[str], int]:
    out: list[str] = []
    buf: list[str] = []
    joined = 0

    def flush() -> None:
        nonlocal joined
        if not buf:
            return
        if len(buf) == 1:
            out.append(buf[0].strip())
        elif all(is_style_only_line(x) for x in buf):
            out.extend(x.strip() for x in buf)
        else:
            out.append(" ".join(x.strip() for x in buf))
            joined += len(buf) - 1
        buf.clear()

    for line in lines:
        if is_structural(line):
            flush()
            out.append(line.rstrip())
        else:
            buf.append(line)
    flush()

    # collapse multiple blank lines to a single blank line
    collapsed: list[str] = []
    blanks = 0
    for line in out:
        if line.strip() == "":
            blanks += 1
            if blanks <= 1:
                collapsed.append("")
        else:
            blanks = 0
            collapsed.append(line)
    return collapsed, joined


def process_file(path: Path, root: Path, pdf_root: Path) -> Counter:
    counts: Counter = Counter()
    text = path.read_text(encoding="utf-8")

    for src, dst in LIGATURES.items():
        c = text.count(src)
        if c:
            text = text.replace(src, dst)
            counts["ligature_replacements"] += c

    lines = text.splitlines()

    # normalize invalid list bullets
    new_lines = []
    for line in lines:
        m = BULLET_RE.match(line)
        if m:
            line = BULLET_RE.sub(r"\1- ", line)
            counts["invalid_bullet_fixed"] += 1
        new_lines.append(line)
    lines = new_lines

    # normalize spaces before punctuation
    text2 = "\n".join(lines)
    text2, c = cleanup_punctuation_spacing(text2)
    counts["punctuation_spacing_fixed"] += c
    lines = text2.splitlines()

    # reflow non-structural wrapped lines
    lines, c = reflow_lines(lines)
    counts["wrapped_lines_joined"] += c

    # normalize heading marker formatting for cleaner anchors / TOC links
    lines, c = normalize_heading_markup(lines)
    counts["heading_markup_normalized"] += c

    # remove legacy in-body Contents/Table of Contents blocks from PDF transcription
    lines, sections_removed, lines_removed = remove_legacy_contents_sections(lines)
    counts["legacy_contents_sections_removed"] += sections_removed
    counts["legacy_contents_lines_removed"] += lines_removed

    lines, c = remove_preamble_toc_fragments(lines)
    counts["preamble_toc_fragments_removed"] += c

    # rebuild TOC (Markdown All in One style markers)
    lines, removed = remove_existing_toc(lines)
    counts["toc_replaced"] += removed
    toc = build_toc(lines)
    if toc:
        counts["toc_inserted"] += 1
        insert_at = 0
        for i, line in enumerate(lines):
            if HEADER_RE.match(line):
                insert_at = i + 1
                break
        lines = lines[:insert_at] + [""] + toc + [""] + lines[insert_at:]

    # add / refresh source PDF link line
    lines, removed = remove_existing_source_line(lines)
    counts["source_link_replaced"] += removed
    rel_md = path.relative_to(root)
    pdf_rel = rel_md.with_suffix(".pdf")
    source_pdf = pdf_root / pdf_rel
    if source_pdf.exists():
        md_dir = path.parent
        rel_link = os.path.relpath(source_pdf, md_dir).replace("\\", "/")
        source_line = f"{SOURCE_PREFIX} [{source_pdf.name}]({rel_link})"
        insert_at = 0
        if TOC_END in lines:
            insert_at = lines.index(TOC_END) + 1
        elif lines and HEADER_RE.match(lines[0]):
            insert_at = 1
        lines = lines[:insert_at] + ["", source_line, ""] + lines[insert_at:]
        counts["source_link_inserted"] += 1
    else:
        counts["source_pdf_missing"] += 1

    out = "\n".join(lines).rstrip() + "\n"
    path.write_text(out, encoding="utf-8")
    return counts


def main() -> int:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--root", default="markdown", help="Markdown root directory")
    parser.add_argument("--pdf-root", default="pdfs", help="PDF root directory")
    args = parser.parse_args()

    root = Path(args.root)
    pdf_root = Path(args.pdf_root)
    files = sorted(root.rglob("*.md"))
    if not files:
        raise SystemExit(f"No markdown files found under {root}")

    total = Counter()
    for f in files:
        counts = process_file(f, root, pdf_root)
        total.update(counts)

    print(f"Processed {len(files)} files")
    for k in sorted(total):
        print(f"{k}: {total[k]}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
